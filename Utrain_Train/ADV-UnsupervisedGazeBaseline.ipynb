{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from UnsupervisedGaze_model import *\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import torch.functional as F\n",
    "from sklearn.utils import shuffle\n",
    "import copy\n",
    "import time\n",
    "import random\n",
    "\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5]),\n",
    "])\n",
    "\n",
    "randseed = 0.4 * np.random.rand(6) + 0.3\n",
    "\n",
    "preprocess_augmentation = transforms.Compose([\n",
    "    transforms.RandomResizedCrop((224, 224), scale=(0.5, 1.0), ratio=(0.95, 1.05)),\n",
    "    transforms.Normalize(mean=randseed[:3], std=randseed[3:]),\n",
    "])\n",
    "\n",
    "class Data_loader():\n",
    "    def __init__(self, path, train_test_ratio = 0.7, augmentation = True, plot_sample = False):\n",
    "        self.dirs = []\n",
    "        self.files_path = []\n",
    "        self.count = []\n",
    "        self.path = path\n",
    "        for each in os.listdir(path):\n",
    "            self.count.append(0)\n",
    "            if each[:2] == '00':\n",
    "                self.dirs.append(each)\n",
    "                self.files_path.append([f.path for f in os.scandir(path+each+'/') if f.is_file() and f.path[-8:]=='_new.jpg'])\n",
    "                self.count[-1] += 1\n",
    "        self.split_index = round(train_test_ratio * len(self.files_path))\n",
    "        print(f\"[Data_loader] training set: {self.split_index} person |\")\n",
    "        print(f\"[Data_loader] test set: {len(self.files_path) - self.split_index} person |\")\n",
    "        self.images_train = []\n",
    "        self.gts_train = []\n",
    "        self.images_test = []\n",
    "        self.gts_test = []\n",
    "        self.augmentation = augmentation\n",
    "\n",
    "    def read_angles(self, name):\n",
    "        filter = name.split(\"/\")[-1].split(\"_\")[3:]\n",
    "        yaw = int(filter[0][:-1])\n",
    "        pitch = int(filter[1].replace(\"H\", ''))\n",
    "        return yaw, pitch\n",
    "\n",
    "    def read_data(self, person, mode=\"TRAIN\"):\n",
    "        temp = []\n",
    "        ang = []\n",
    "        for file_name in person:\n",
    "            yaw, pitch = self.read_angles(file_name)\n",
    "            with Image.open(file_name) as image:\n",
    "              image_matrix = preprocess(image)\n",
    "            if self.augmentation and mode==\"TRAIN\" and np.random.randint(0,100) > 63:\n",
    "                image_matrix_augmentation = preprocess_augmentation(image_matrix)\n",
    "                temp.append(image_matrix_augmentation)\n",
    "                ang.append([yaw, pitch])\n",
    "            temp.append(image_matrix)\n",
    "            ang.append([yaw, pitch])\n",
    "        if mode == \"TRAIN\":\n",
    "            self.images_train.extend(temp)\n",
    "            self.gts_train.extend(ang)\n",
    "        else:\n",
    "            self.images_test.extend(temp)\n",
    "            self.gts_test.extend(ang)\n",
    "\n",
    "    def get_data(self):\n",
    "        for i, person in enumerate(self.files_path):\n",
    "            if i >= self.split_index:\n",
    "                self.read_data(person, mode=\"TEST\")\n",
    "            self.read_data(person)\n",
    "        return self.images_train, self.gts_train, self.images_test, self.gts_test\n",
    "\n",
    "ColumbiaGazeDataset = Data_loader(path = \"/root/Columbia Gaze Data Set/\")\n",
    "images_train, gts_train, images_test, gts_test = ColumbiaGazeDataset.get_data()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on : \", device)\n",
    "print(f\"Number of training images : {len(images_train)} test: {len(images_test)}\")\n",
    "\n",
    "images_train, images_test = torch.stack(images_train).to(device), torch.stack(images_test).to(device)\n",
    "gts_train, gts_test = torch.tensor(gts_train).to(device), torch.tensor(gts_test).to(device)\n",
    "\n",
    "class LinfPGDAttack(object):\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "        self.epsilon = 0.0314\n",
    "        self.k = 7\n",
    "        self.alpha = 0.00784\n",
    "\n",
    "    def perturb(self, x_natural, y):\n",
    "        x = x_natural.detach()\n",
    "        x = x + torch.zeros_like(x).uniform_(-self.epsilon, self.epsilon)\n",
    "        for i in range(self.k):\n",
    "            x.requires_grad_()\n",
    "            with torch.enable_grad():\n",
    "                logits = self.model(x)\n",
    "                loss = nn.L1Loss()(logits, y)\n",
    "            grad = torch.autograd.grad(loss, [x])[0]\n",
    "            x = x.detach() + self.alpha * torch.sign(grad.detach())\n",
    "            x = torch.min(torch.max(x, x_natural - self.epsilon), x_natural + self.epsilon)\n",
    "            x = torch.clamp(x, 0, 1)\n",
    "        return x\n",
    "\n",
    "def attack(x, y, model, adversary):\n",
    "    model_copied = copy.deepcopy(model).to(device)\n",
    "    model_copied.eval()\n",
    "    adversary.model = model_copied.to(device)\n",
    "    adv = adversary.perturb(x, y)\n",
    "    return adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Running on : \", device)\n",
    "\n",
    "def find_abs_angle_difference(a, b):\n",
    "    cos_theta = torch.cos(a/180 * math.pi) * torch.cos(b/180 * math.pi) \n",
    "    theta = torch.acos(cos_theta)\n",
    "    return torch.abs(theta * 180 / math.pi)\n",
    "\n",
    "def test_baseline(data, number_of_epoch = 250, lr=5e-5, weight_decay=1e-4, batch_size = 16, show_images=False):\n",
    "    images = data[0]\n",
    "    gts = data[1]\n",
    "    images_test = data[2]\n",
    "    gts_test = data[3]\n",
    "    loss_hist = []\n",
    "    if show_images:\n",
    "        for _ in range(2):\n",
    "            num = np.random.randint(0, len(data))\n",
    "            plt.imshow(images[num, 0, :, :])\n",
    "            plt.title(f\"{data[num][1]}\")\n",
    "            plt.show()\n",
    "    model = GazeRepresentationLearning_fullface()\n",
    "    model.to(device)\n",
    "    criterion = nn.L1Loss()\n",
    "    adver = LinfPGDAttack(model)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    for epoch in range(number_of_epoch):\n",
    "        prev = time.time()\n",
    "        model.train()\n",
    "        for i in range(images.size(0)//batch_size):\n",
    "            image_1 = images[batch_size*i:batch_size*(i+1)].to(device)\n",
    "            outputs = model(image_1)\n",
    "            gt = gts[batch_size*i:batch_size*(i+1)].to(device)\n",
    "            if show_images and np.random.randint(0, 1000) > 990:\n",
    "                plt.imshow(image_1[0,0,:,:])\n",
    "                plt.title(f'ground truth = {gt}, output = {outputs}')\n",
    "                plt.show()\n",
    "            if epoch % 50 == 0 and i==0:\n",
    "                for g in optimizer.param_groups:\n",
    "                    g['lr'] /= 2\n",
    "                print(\"reduce lr\")\n",
    "            loss = criterion(outputs, gts[batch_size*i:batch_size*(i+1)])\n",
    "            loss_hist.append(loss)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        # print(f'{time.time()-prev} second for training')\n",
    "        if epoch%20 == 0:\n",
    "            print(f'epoch: {epoch+1}, loss: {loss}')\n",
    "        torch.save(model, f\"/root/_KD/ADV_UnsupervisedBaseline_log_8/full_log/adv_baseline_{epoch=}_loss={float(loss)}_{batch_size=}_{weight_decay=}.pt\")\n",
    "\n",
    "        model.eval()\n",
    "        prev = time.time()\n",
    "        adv_loss = 0\n",
    "        benign_loss = 0\n",
    "        total = 0\n",
    "        benign_correct = 0\n",
    "        adv_correct = 0\n",
    "        with torch.no_grad():\n",
    "            for i in range(images.size(0)//batch_size):\n",
    "                image_1 = images[batch_size*i:batch_size*(i+1)].to(device)\n",
    "                outputs = model(image_1)\n",
    "                gt = gts[batch_size*i:batch_size*(i+1)].to(device)\n",
    "                loss = criterion(outputs, gt)\n",
    "\n",
    "                benign_loss += loss.item()\n",
    "                adv = adver.perturb(image_1, gt)\n",
    "                adv_outputs = model(adv)\n",
    "                loss = criterion(adv_outputs, gt)\n",
    "        # print(f'{time.time()-prev} second for adversarial')\n",
    "    outputs = model(images_test)\n",
    "    dif = gts_test - outputs\n",
    "    yaw = dif[:, 0]\n",
    "    pitch = dif[:, 1]\n",
    "    val = find_abs_angle_difference(yaw, pitch)\n",
    "    error = torch.sum(val/outputs.size(0))\n",
    "    print(f\": got mean angle error: {error}\")\n",
    "    torch.save(model, f\"/root/_KD/ADV_UnsupervisedBaseline_log_8/adv_final_baseline_error={float(error)}.pt\")\n",
    "test_baseline((images_train, gts_train, images_test, gts_test), number_of_epoch = 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "UGaze",
   "language": "python",
   "name": "ugaze"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f31e168fba78b4b36275f185ec84f7848f530d4b6bcb201f71fda065d51c4410"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
